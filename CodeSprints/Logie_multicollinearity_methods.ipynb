{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "204733d1",
   "metadata": {},
   "source": [
    "## Multicollinearity and Regression Analysis\n",
    "In this tutorial, we will be using a spatial dataset of county-level election and demographic statistics for the United States. This time, we'll explore different methods to diagnose and account for multicollinearity in our data. Specifically, we'll calculate variance inflation factor (VIF), and compare parameter estimates and model fit in a multivariate regression predicting 2016 county voting preferences using an OLS model, a ridge regression, a lasso regression, and an elastic net regression.\n",
    "\n",
    "Objectives:\n",
    "* ***Calculate a variance inflation factor to diagnose multicollinearity.***\n",
    "* ***Use geographicall weighted regression to identify if the multicollinearity is scale dependent.***\n",
    "* ***Interpret model summary statistics.***\n",
    "* ***Describe how multicollinearity impacts stability in parameter esimates.***\n",
    "* ***Explain the variance/bias tradeoff and describe how to use it to improve models***\n",
    "* ***Draw a conclusion based on contrasting models.***\n",
    "\n",
    "Review: \n",
    "* [Dormann, C. et al. (2013). Collinearity: a review of methods to deal with it and a simulation study evaluating their performance. Ecography, 36(1), 27-46.](https://onlinelibrary.wiley.com/doi/full/10.1111/j.1600-0587.2012.07348.x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf668f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tylerlogie/opt/anaconda3/envs/geostats_env/lib/python3.8/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from libpysal.weights.contiguity import Queen\n",
    "import libpysal\n",
    "from statsmodels.api import OLS\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daec4204",
   "metadata": {},
   "source": [
    "First, we're going to load the 'Elections' dataset from the libpysal library, which is a very easy to use API that accesses the Geodata Center at the University of Chicago.\n",
    "\n",
    "* More on spatial data science resources from UC: https://spatial.uchicago.edu/\n",
    "* A list of datasets available through lipysal: https://geodacenter.github.io/data-and-lab//"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de38c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example not available: Elections\n",
      "Downloading AirBnB to /Users/tylerlogie/pysal_data/AirBnB\n",
      "Downloading Atlanta to /Users/tylerlogie/pysal_data/Atlanta\n",
      "Downloading Baltimore to /Users/tylerlogie/pysal_data/Baltimore\n",
      "Downloading Bostonhsg to /Users/tylerlogie/pysal_data/Bostonhsg\n",
      "Downloading Buenosaires to /Users/tylerlogie/pysal_data/Buenosaires\n",
      "Downloading Charleston1 to /Users/tylerlogie/pysal_data/Charleston1\n",
      "Downloading Charleston2 to /Users/tylerlogie/pysal_data/Charleston2\n",
      "Downloading Chicago Health to /Users/tylerlogie/pysal_data/Chicago_Health\n",
      "Downloading Chicago commpop to /Users/tylerlogie/pysal_data/Chicago_commpop\n",
      "Example not downloaded: Chicago parcels\n",
      "Downloading Chile Labor to /Users/tylerlogie/pysal_data/Chile_Labor\n",
      "Example not downloaded: Chile Migration\n",
      "Downloading Cincinnati to /Users/tylerlogie/pysal_data/Cincinnati\n",
      "Downloading Cleveland to /Users/tylerlogie/pysal_data/Cleveland\n",
      "Downloading Columbus to /Users/tylerlogie/pysal_data/Columbus\n",
      "Downloading Elections to /Users/tylerlogie/pysal_data/Elections\n",
      "Downloading Grid100 to /Users/tylerlogie/pysal_data/Grid100\n",
      "Downloading Groceries to /Users/tylerlogie/pysal_data/Groceries\n",
      "Downloading Guerry to /Users/tylerlogie/pysal_data/Guerry\n",
      "Downloading Health Indicators to /Users/tylerlogie/pysal_data/Health_Indicators\n",
      "Downloading Health+ to /Users/tylerlogie/pysal_data/Health+\n",
      "Downloading Hickory1 to /Users/tylerlogie/pysal_data/Hickory1\n",
      "Downloading Hickory2 to /Users/tylerlogie/pysal_data/Hickory2\n",
      "Downloading Home Sales to /Users/tylerlogie/pysal_data/Home_Sales\n",
      "Downloading Houston to /Users/tylerlogie/pysal_data/Houston\n",
      "Downloading Juvenile to /Users/tylerlogie/pysal_data/Juvenile\n",
      "Downloading Lansing1 to /Users/tylerlogie/pysal_data/Lansing1\n",
      "Downloading Lansing2 to /Users/tylerlogie/pysal_data/Lansing2\n",
      "Downloading Laozone to /Users/tylerlogie/pysal_data/Laozone\n",
      "Downloading LasRosas to /Users/tylerlogie/pysal_data/LasRosas\n",
      "Downloading Liquor Stores to /Users/tylerlogie/pysal_data/Liquor_Stores\n",
      "Downloading Malaria to /Users/tylerlogie/pysal_data/Malaria\n",
      "Downloading Milwaukee1 to /Users/tylerlogie/pysal_data/Milwaukee1\n",
      "Downloading Milwaukee2 to /Users/tylerlogie/pysal_data/Milwaukee2\n",
      "Downloading NCOVR to /Users/tylerlogie/pysal_data/NCOVR\n",
      "Downloading NDVI to /Users/tylerlogie/pysal_data/NDVI\n",
      "Downloading NYC to /Users/tylerlogie/pysal_data/NYC\n",
      "Downloading NYC Earnings to /Users/tylerlogie/pysal_data/NYC_Earnings\n",
      "Downloading NYC Education to /Users/tylerlogie/pysal_data/NYC_Education\n",
      "Downloading NYC Neighborhoods to /Users/tylerlogie/pysal_data/NYC_Neighborhoods\n",
      "Downloading NYC Socio-Demographics to /Users/tylerlogie/pysal_data/NYC_Socio-Demographics\n",
      "Downloading Natregimes to /Users/tylerlogie/pysal_data/Natregimes\n",
      "Downloading Nepal to /Users/tylerlogie/pysal_data/Nepal\n",
      "Downloading Ohiolung to /Users/tylerlogie/pysal_data/Ohiolung\n",
      "Downloading Orlando1 to /Users/tylerlogie/pysal_data/Orlando1\n",
      "Downloading Orlando2 to /Users/tylerlogie/pysal_data/Orlando2\n",
      "Downloading Oz9799 to /Users/tylerlogie/pysal_data/Oz9799\n",
      "Downloading Phoenix ACS to /Users/tylerlogie/pysal_data/Phoenix_ACS\n",
      "Downloading Pittsburgh to /Users/tylerlogie/pysal_data/Pittsburgh\n",
      "Downloading Police to /Users/tylerlogie/pysal_data/Police\n",
      "Downloading Rio Grande do Sul to /Users/tylerlogie/pysal_data/Rio_Grande_do_Sul\n",
      "Downloading SIDS to /Users/tylerlogie/pysal_data/SIDS\n",
      "Downloading SIDS2 to /Users/tylerlogie/pysal_data/SIDS2\n",
      "Downloading Sacramento1 to /Users/tylerlogie/pysal_data/Sacramento1\n",
      "Downloading Sacramento2 to /Users/tylerlogie/pysal_data/Sacramento2\n",
      "Downloading SanFran Crime to /Users/tylerlogie/pysal_data/SanFran_Crime\n",
      "Downloading Savannah1 to /Users/tylerlogie/pysal_data/Savannah1\n",
      "Downloading Savannah2 to /Users/tylerlogie/pysal_data/Savannah2\n",
      "Downloading Scotlip to /Users/tylerlogie/pysal_data/Scotlip\n",
      "Downloading Seattle1 to /Users/tylerlogie/pysal_data/Seattle1\n",
      "Downloading Seattle2 to /Users/tylerlogie/pysal_data/Seattle2\n",
      "Downloading Snow to /Users/tylerlogie/pysal_data/Snow\n",
      "Downloading South to /Users/tylerlogie/pysal_data/South\n",
      "Example not downloaded: Spirals\n",
      "Downloading StLouis to /Users/tylerlogie/pysal_data/StLouis\n",
      "Downloading Tampa1 to /Users/tylerlogie/pysal_data/Tampa1\n",
      "Downloading US SDOH to /Users/tylerlogie/pysal_data/US_SDOH\n",
      "Downloading clearwater to /Users/tylerlogie/pysal_data/clearwater\n",
      "Downloading newHaven to /Users/tylerlogie/pysal_data/newHaven\n"
     ]
    }
   ],
   "source": [
    "from libpysal.examples import load_example\n",
    "elections = load_example('Elections')\n",
    "#note the folder where your data now lives:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7fe6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, let's see what files are available in the 'Elections' data example\n",
    "elections.get_file_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92c29a3",
   "metadata": {},
   "source": [
    "When you are out in the world doing research, you often will not find a ready-made function to download your data. That's okay! You know how to get this dataset without using pysal! Do a quick internal review of online data formats and automatic data downloads.\n",
    "\n",
    "### TASK 1: Use urllib functions to download this file directly from the internet to you H:/EnvDatSci folder (not your git repository). Extract the zipped file you've downloaded into a subfolder called H:/EnvDatSci/elections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1318b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 code here:\n",
    "#import required function:\n",
    "import urllib.request\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "#define online filepath (aka url):\n",
    "online_path = \"https://geodacenter.github.io/data-and-lab//data/election.zip\"\n",
    "\n",
    "#define local filepath:\n",
    "local_path = \"/Users/tylerlogie/Documents/School_Work_Fall_2021/EnvDatSci/elections.zip\"\n",
    "\n",
    "#download elections data:\n",
    "urllib.request.urlretrieve(online_path, local_path)\n",
    "\n",
    "#unzip file: see if google can help you figure this one out!\n",
    "os.chdir(\"/Users/tylerlogie/Documents/School_Work_Fall_2021/EnvDatSci/\")\n",
    "with ZipFile(\"elections.zip\", 'r') as zip:\n",
    "   zip.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea133475",
   "metadata": {},
   "source": [
    "### TASK 2: Use geopandas to read in this shapefile. Call your geopandas.DataFrame \"votes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81455057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 2: Use geopandas to read in this shapefile. Call your geopandas.DataFrame \"votes\"\n",
    "os.chdir(\"election\")\n",
    "votes = gpd.read_file(\"election.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c603c7b4",
   "metadata": {},
   "source": [
    "### EXTRA CREDIT TASK (+2pts): use os to delete the elections data downloaded by pysal in your C: drive that you are no longer using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9d8bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra credit task:\n",
    "import shutil\n",
    "path = \"/Users/tylerlogie/pysal_data/\"\n",
    "shutil.rmtree(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae67e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's view the shapefile to get a general idea of the geometry we're looking at:\n",
    "%matplotlib inline\n",
    "votes.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7495565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the first few line]s of the dataset\n",
    "votes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813ad89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since there are too many columns for us to view on a signle page using \"head\", we can just print out the column names so we have them all listed for reference\n",
    "for col in votes.columns: \n",
    "    print(col) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa277c42",
   "metadata": {},
   "source": [
    "#### You can use pandas summary statistics to get an idea of how county-level data varies across the United States. \n",
    "### TASK 3: For example, how did the county mean percent Democratic vote change between 2012 (pct_dem_12) and 2016 (pct_dem_16)?\n",
    "\n",
    "Look here for more info on pandas summary statistics:https://www.earthdatascience.org/courses/intro-to-earth-data-science/scientific-data-structures-python/pandas-dataframes/run-calculations-summary-statistics-pandas-dataframes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818f70e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 3\n",
    "print(votes.pct_dem_12.describe())\n",
    "print(votes.pct_dem_16.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0f15a0",
   "metadata": {},
   "source": [
    "We can also plot histograms of the data. Below, smoothed histograms from the seaborn package (imported as sns) let us get an idea of the distribution of percent democratic votes in 2012 (left) and 2016 (right)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57df83a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms:\n",
    "f,ax = plt.subplots(1,2, figsize=(2*3*1.6, 2))\n",
    "for i,col in enumerate(['pct_dem_12','pct_dem_16']):\n",
    "    sns.kdeplot(votes[col].values, shade=True, color='slategrey', ax=ax[i])\n",
    "    ax[i].set_title(col.split('_')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c314d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot spatial distribution of # dem vote in 2012 and 2016 with histogram.\n",
    "f,ax = plt.subplots(2,2, figsize=(1.6*6 + 1,2.4*3), gridspec_kw=dict(width_ratios=(6,1)))\n",
    "for i,col in enumerate(['pct_dem_12','pct_dem_16']):\n",
    "    votes.plot(col, linewidth=.05, cmap='RdBu', ax=ax[i,0])\n",
    "    ax[i,0].set_title(['2012','2016'][i] + \"% democratic vote\")\n",
    "    ax[i,0].set_xticklabels('')\n",
    "    ax[i,0].set_yticklabels('')\n",
    "    sns.kdeplot(votes[col].values, ax=ax[i,1], vertical=True, shade=True, color='slategrey')\n",
    "    ax[i,1].set_xticklabels('')\n",
    "    ax[i,1].set_ylim(-1,1)\n",
    "f.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d6ec1f",
   "metadata": {},
   "source": [
    "### TASK 4: Make a new column on your geopandas dataframe called \"pct_dem_change\" and plot it using the syntax above. Explain the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68ce3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: add new column pct_dem_change to votes:\n",
    "votes[\"pct_dem_change\"] = votes[\"pct_dem_16\"] - votes[\"pct_dem_12\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c7a89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 4: plot your pct_dem_change variable on a map:\n",
    "f,ax = plt.subplots(3,2, figsize=(1.6*6 + 1,2.4*3), gridspec_kw=dict(width_ratios=(6,1)))\n",
    "for i,col in enumerate(['pct_dem_12','pct_dem_16',\"pct_dem_change\"]):\n",
    "    votes.plot(col, linewidth=.05, cmap='RdBu', ax=ax[i,0])\n",
    "    ax[i,0].set_title(['2012','2016','Change in'][i] + \"% democratic vote\")\n",
    "    ax[i,0].set_xticklabels('')\n",
    "    ax[i,0].set_yticklabels('')\n",
    "    sns.kdeplot(votes[col].values, ax=ax[i,1], vertical=True, shade=True, color='slategrey')\n",
    "    ax[i,1].set_xticklabels('')\n",
    "    ax[i,1].set_ylim(-1,1)\n",
    "f.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946cb5c6",
   "metadata": {},
   "source": [
    "Click on this url to learn more about the variables in this dataset: https://geodacenter.github.io/data-and-lab//county_election_2012_2016-variables/\n",
    "As you can see, there are a lot of data values available in this dataset. Let's say we want to learn more about what county-level factors influence percent change in democratic vote between (pct_dem_change).\n",
    "\n",
    "Looking at the data description on the link above, you see that this is an exceptionally large dataset with many variables. During lecture, we discussed how there are two types of multicollinearity in our data:\n",
    "\n",
    "* *Intrinsic multicollinearity:* is an artifact of how we make observations. Often our measurements serve as proxies for some latent process (for example, we can measure percent silt, percent sand, and percent clay as proxies for the latent variable of soil texture). There will be slight variability in the information content between each proxy measurement, but they will not be independent of one another.\n",
    "\n",
    "* *Incidental collinearity:* is an artifact of how we sample complex populations. If we collect data from a subsample of the landscape where we don't see all combinations of our predictor variables (do not have good cross replication across our variables). We often induce collinearity in our data just because we are limitted in our ability to sample the environment at the scale of temporal/spatial variability of our process of interest. Incidental collinearity is a model formulation problem.(See here for more info on how to avoid it: https://people.umass.edu/sdestef/NRC%20601/StudyDesignConcepts.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5b59ac",
   "metadata": {},
   "source": [
    "### TASK 5: Looking at the data description, pick two variables that you believe will be intrinsically multicollinear. List and describe these variables. Why do you think they will be collinear? Is this an example of *intrinsic* or *incidental* collinearity?\n",
    "\n",
    "I chose:   \n",
    "* \"pct_dem_16\", #Votes for Democratic candidate as percent of total votes\n",
    "* \"pct_gop_16\", #Votes for Republican candidate as percent of total votes\n",
    "<br>These variables are intrinsically multicollinear. Third party votes are a relatively small portion of the total, so the percentage of democratic and republican votes in a county are likely to be directly inversely correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18207d3e",
   "metadata": {},
   "source": [
    "## Multivariate regression in observational data:\n",
    "Our next step is to formulate our predictive/diagnostic model. We want to create a subset of the \"votes\" geopandas data frame that contains ten predictor variables and our response variable (pct_pt_16) two variables you selected under TASK 1. First, create a list of the variables you'd like to select.\n",
    "\n",
    "### TASK 6: Create a subset of votes called \"my_list\" containing only your selected predictor variables. Make sure you use the two variables selected under TASK 3, and eight additional variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973df305",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "votes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d4c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: create a subset of votes called \"my list\" with all your subset variables.\n",
    "my_list = [\"pct_pt_16\", 'AGE775214', 'RHI125214','EDU685213', 'POP060210', 'RTN131207', 'BZA115213', 'POP815213', \"pct_dem_16\", 'pct_gop_16']      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1835a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to make sure all your columns are there:\n",
    "votes[my_list].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28d9dc4",
   "metadata": {},
   "source": [
    "### Scatterplot matrix\n",
    "We call the process of getting to know your data (ranges and distributions of the data, as well as any relationships between variables) \"exploratory data analysis\". Pairwise plots of your variables, called scatterplots, can provide a lot of insight into the type of relationships you have between variables. A scatterplot matrix is a pairwise comparison of all variables in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f67ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use seaborn.pairplot to plot a scatterplot matrix of you 10 variable subset:\n",
    "sns.pairplot(votes[my_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b1b309",
   "metadata": {},
   "source": [
    "### TASK 7: Do you observe any collinearity in this dataset? How would you describe the relationship between your two \"intrinsically collinear\" variables that you selected based on looking at variable descriptions? \n",
    "\n",
    "The intrinsically collinear variables (republican and democrat vote percentage) are highly collinear. While some of the other variables do appear somewhat correlated, none appear to be collinear. \n",
    "\n",
    "\n",
    "### TASK 8: What is plotted on the diagonal panels of the scatterplot matrix?\n",
    "\n",
    "The diagonal panels in the matrix occur in locations where the column and row values are equivalent, and have histograms plotted instead of scatterplots. These histograms show the relative abundance of all of the values for that category (binned). The x axis shows the binned values, the y axis shows the number of values within that bin. These histograms show that some variables have a more even distribution, while some are heavily skewed and others have a narrow range of values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b42b91",
   "metadata": {},
   "source": [
    "## Diagnosing collinearity globally:\n",
    "During class, we discussed the Variance Inflation Factor, which describes the magnitude of variance inflation that can be expected in an OLS parameter estimate for a given variable *given pairwise collinearity between that variable and another variable*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be64d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VIF = 1/(1-R2) of a pairwise OLS regression between two predictor variables\n",
    "#We can use a built-in function \"variance_inflation_factor\" from statsmodel.api to calculate VIF\n",
    "#Learn more about the function\n",
    "?variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53f51dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate VIFs on our dataset\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(votes[my_list[1:10]].values, i) for i in range(votes[my_list[1:10]].shape[1])]\n",
    "vif[\"features\"] = votes[my_list[1:10]].columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d465f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif.round()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae322791",
   "metadata": {},
   "source": [
    "### Collinearity is always present in observational data. When is it a problem?\n",
    "Generally speaking, VIF > 10 are considered \"too much\" collinearity. But this value is somewhat arbitrary: the extent to which variance inflation will impact your analysis is highly context dependent. There are two primary contexts where variance inflation is problematic:\n",
    "\n",
    " 1\\. **You are using your analysis to evaluate variable importance:** If you are using parameter estimates from your model to diagnose which observations have physically important relationships with your response variable, variance inflation can make an important predictor look unimportant, and parameter estimates will be highly leveraged by small changes in the data. \n",
    "\n",
    " 2\\. **You want to use your model to make predictions in a situation where the specific structure of collinearity between variables may have shifted:** When training a model on collinear data, the model only applies to data with that exact structure of collinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a7a711",
   "metadata": {},
   "source": [
    "### Calculate a linear regression on the global data:\n",
    "In this next step, we're going to calculate a linear regression in our data an determine whether there is a statistically significant relationship between per capita income and percent change in democratic vote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515911da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, forumalate the model. See weather_trend.py in \"Git_101\" for a refresher on how.\n",
    "\n",
    "#extract variable that you want to use to \"predict\"\n",
    "X = np.array(votes[my_list[1:10]].values)\n",
    "#standardize data to assist in interpretation of coefficients\n",
    "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "\n",
    "#extract variable that we want to \"predict\"\n",
    "Y = np.array(votes['pct_dem_change'].values)\n",
    "#standardize data to assist in interpretation of coefficients\n",
    "Y = (Y - np.mean(X)) / np.std(Y)\n",
    "\n",
    "lm = OLS(Y,X)\n",
    "lm_results = OLS(Y,X).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a265a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lm_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d760fd73",
   "metadata": {},
   "source": [
    "### TASK 9: Answer: which coefficients indicate a statistically significant relationship between parameter and pct_dem_change? What is your most important predictor variable? How can you tell?\n",
    "\n",
    "Coefficients indicate statistically significant relationships, with values closer to 1 indicating a positive relationship and values close to -1 a negative relationship. The most important predictors are x9 and x3, which correspond to the percent republican vote and the percent of people over 25 with a bachelors degree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1202f4f3",
   "metadata": {},
   "source": [
    "### TASK10:  Are any of these parameters subject to variance inflation? How can you tell?\n",
    "\n",
    "All of the parameters except for population density and private non-farm employment change are heavily affected by variance inflation, as the VIF is significantly more than 1 for all other parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25a9235",
   "metadata": {},
   "source": [
    "Now, let's plot our residuals to see if there are any spatial patterns in them.\n",
    "\n",
    "Remember residuals = predicted - fitted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0098b6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add model residuals to our \"votes\" geopandas dataframe:\n",
    "votes['lm_resid']=OLS(Y,X).fit().resid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a439b312",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(votes['lm_resid'].values, shade=True, color='slategrey')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc83f6a",
   "metadata": {},
   "source": [
    "### TASK 11: Are our residuals normally distributed with a mean of zero? What does that mean?\n",
    "\n",
    "The values are distributed around a mean value of approximately -1.2 instead of zero, and have a negative skew around the mean (longer tail on the negative side. This indicates that the variables are not independent of each other, and there is multicollinearity affecting the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f59dce",
   "metadata": {},
   "source": [
    "## Penalized regression: ridge penalty\n",
    "In penalized regression, we intentionally bias the parameter estimates to stabilize them given collinearity in the dataset.\n",
    "\n",
    "From https://www.analyticsvidhya.com/blog/2016/01/ridge-lasso-regression-python-complete-tutorial/\n",
    "\"As mentioned before, ridge regression performs ‘L2 regularization‘, i.e. it adds a factor of sum of squares of coefficients in the optimization objective. Thus, ridge regression optimizes the following:\n",
    "\n",
    "**Objective = RSS + α * (sum of square of coefficients)**\n",
    "\n",
    "Here, α (alpha) is the parameter which balances the amount of emphasis given to minimizing RSS vs minimizing sum of square of coefficients. α can take various values:\n",
    "\n",
    "* **α = 0:** The objective becomes same as simple linear regression. We’ll get the same coefficients as simple linear regression.\n",
    "\n",
    "* **α = ∞:** The coefficients will approach zero. Why? Because of infinite weightage on square of coefficients, anything less than zero will make the objective infinite.\n",
    "\n",
    "* **0 < α < ∞:** The magnitude of α will decide the weightage given to different parts of objective. The coefficients will be somewhere between 0 and ones for simple linear regression.\"\n",
    "\n",
    "In other words, the ridge penalty shrinks coefficients such that collinear coefficients will have more similar coefficient values. It has a \"grouping\" tendency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebcc4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when L2=0, Ridge equals OLS\n",
    "model = Ridge(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b4d30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, Y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "#force scores to be positive\n",
    "scores = absolute(scores)\n",
    "print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68402c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,Y)\n",
    "#Print out the model coefficients\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d94d1f",
   "metadata": {},
   "source": [
    "## Penalized regression: lasso penalty\n",
    "\n",
    "From https://www.analyticsvidhya.com/blog/2016/01/ridge-lasso-regression-python-complete-tutorial/\n",
    "\"LASSO stands for Least Absolute Shrinkage and Selection Operator. I know it doesn’t give much of an idea but there are 2 key words here – ‘absolute‘ and ‘selection‘.\n",
    "\n",
    "Lets consider the former first and worry about the latter later.\n",
    "\n",
    "Lasso regression performs L1 regularization, i.e. it adds a factor of sum of absolute value of coefficients in the optimization objective. Thus, lasso regression optimizes the following:\n",
    "\n",
    "**Objective = RSS + α * (sum of absolute value of coefficients)**\n",
    "Here, α (alpha) works similar to that of ridge and provides a trade-off between balancing RSS and magnitude of coefficients. Like that of ridge, α can take various values. Lets iterate it here briefly:\n",
    "\n",
    "* **α = 0:** Same coefficients as simple linear regression\n",
    "* **α = ∞:** All coefficients zero (same logic as before)\n",
    "* **0 < α < ∞:** coefficients between 0 and that of simple linear regression\n",
    "\n",
    "Yes its appearing to be very similar to Ridge till now. But just hang on with me and you’ll know the difference by the time we finish.\"\n",
    "\n",
    "In other words, the lasso penalty shrinks unimportant coefficients down towards zero, automatically \"selecting\" important predictor variables. But what if that shrunken coefficient is induced by incidental collinearity (i.e. is a feature of how we sampled our data)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f683d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when L1=0, Lasso equals OLS\n",
    "model = Lasso(alpha=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eccdbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, Y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "#force scores to be positive\n",
    "scores = absolute(scores)\n",
    "print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd8e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,Y)\n",
    "#Print out the model coefficients\n",
    "print(model.coef_)\n",
    "#How do these compare with OLS coefficients above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2b1fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when L1 approaches infinity, certain coefficients will become exactly zero, and MAE equals the variance of our response variable:\n",
    "model = Lasso(alpha=10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd284dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, Y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "#force scores to be positive\n",
    "scores = absolute(scores)\n",
    "print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2dd989",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,Y)\n",
    "#Print out the model coefficients\n",
    "print(model.coef_)\n",
    "#How do these compare with OLS coefficients above?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe1b7ff",
   "metadata": {},
   "source": [
    "### Penalized regression: elastic net penalty\n",
    "\n",
    "In other words, the lasso penalty shrinks unimportant coefficients down towards zero, automatically \"selecting\" important predictor variables. The ridge penalty shrinks coefficients of collinear predictor variables nearer to each other, effectively partitioning the magnitude of response from the response variable between them, instead of \"arbitrarily\" partitioning it to one group.\n",
    "\n",
    "We can also run a regression with a linear combination of ridge and lasso, called the elastic net, that has a cool property called \"group selection.\"\n",
    "\n",
    "The ridge penalty still works to distribute response variance equally between members of \"groups\" of collinear predictor variables. The lasso penalty still works to shrink certain coefficients to exactly zero so they can be ignored in model formulation. The elastic net produces models that are both sparse and stable under collinearity, by shrinking parameters of members of unimportant collinear predictor variables to exactly zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6967ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when L1 approaches infinity, certain coefficients will become exactly zero, and MAE equals the variance of our response variable:\n",
    "model = ElasticNet(alpha=1, l1_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fc92a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, Y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "#force scores to be positive\n",
    "scores = absolute(scores)\n",
    "print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fee71d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X,Y)\n",
    "#Print out the model coefficients\n",
    "print(model.coef_)\n",
    "#How do these compare with OLS coefficients above?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8a540d",
   "metadata": {},
   "source": [
    "### TASK 12: Match these elastic net coefficients up with your original data. Do you see a logical grouping(s) between variables that have non-zero coefficients? Explain why or why not.\n",
    "\n",
    "The non-zero elastic net coefficients correspond to people over 65, white population, percent of people with bachelors, and percent of households with non-English languages spoken at home. None of these coefficients appear to form a clear group with each other. The two negative coefficients, over 65 and white population, may be grouped as there is more racial diversity in younger age groups. The two positive variables, non-English home language and bachelors degree, may also be correlated, but I am not sure about the connection between the two either way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39154fe7",
   "metadata": {},
   "source": [
    "### Task 12 scratch cell:\n",
    "Name: AGE775214 Coeff: -0.02790138  \n",
    "Name: RHI125214 Coeff: -0.07411806  \n",
    "Name: EDU685213 Coeff: 0.13935717  \n",
    "Name: POP815213 Coeff: 0.07844104  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geostats_env",
   "language": "python",
   "name": "geostats_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
